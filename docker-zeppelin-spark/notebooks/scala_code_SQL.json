{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541150956213_355015491","id":"20181102-092916_1989857282","dateCreated":"2018-11-02T09:29:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6434","text":"import org.apache.spark.sql.expressions.Window\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.Row\n\nval JOIN_COLUMN: String = \"rn\"\n\n//definicion de una funcion que aplica un join entre dos dataframes y devuelve\n//otro data frame como resultado\ndef joinDataFrames(df: DataFrame, df2: DataFrame,joinCol: String) : DataFrame = {\n    df.registerTempTable(\"df1\")\n    df2.registerTempTable(\"df2\")\n    sqlContext.sql(\"\"+\n                \"SELECT \"+\n                    \"df1.* \"+\n                \"FROM df1  \"+\n                \"INNER JOIN  \"+\n                \"df2 ON df1.rn=df2.rn\"\n                )\n}\n    \n//origen de datos\nval data =\"/data/slice_violations.csv\"\n//dataframe con los datos cargados\nval df = spark.read.format(\"csv\").option(\"header\", \"true\").load(data)\ndf.printSchema()\ndf.limit(1).show()","dateUpdated":"2018-11-02T09:44:56+0000","dateFinished":"2018-11-02T09:44:58+0000","dateStarted":"2018-11-02T09:44:56+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.expressions.Window\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.Row\nJOIN_COLUMN: String = rn\nwarning: there were two deprecation warnings; re-run with -deprecation for details\njoinDataFrames: (df: org.apache.spark.sql.DataFrame, df2: org.apache.spark.sql.DataFrame, joinCol: String)org.apache.spark.sql.DataFrame\ndata: String = /data/slice_violations.csv\ndf: org.apache.spark.sql.DataFrame = [date_of_stop: string, time_of_stop: string ... 33 more fields]\nroot\n |-- date_of_stop: string (nullable = true)\n |-- time_of_stop: string (nullable = true)\n |-- agency: string (nullable = true)\n |-- subagency: string (nullable = true)\n |-- description: string (nullable = true)\n |-- location: string (nullable = true)\n |-- latitude: string (nullable = true)\n |-- longitude: string (nullable = true)\n |-- accident: string (nullable = true)\n |-- belts: string (nullable = true)\n |-- personal_injury: string (nullable = true)\n |-- property_damage: string (nullable = true)\n |-- fatal: string (nullable = true)\n |-- commercial_license: string (nullable = true)\n |-- hazmat: string (nullable = true)\n |-- commercial_vehicle: string (nullable = true)\n |-- alcohol: string (nullable = true)\n |-- work_zone: string (nullable = true)\n |-- state: string (nullable = true)\n |-- vehicletype: string (nullable = true)\n |-- year: string (nullable = true)\n |-- make: string (nullable = true)\n |-- model: string (nullable = true)\n |-- color: string (nullable = true)\n |-- violation_type: string (nullable = true)\n |-- charge: string (nullable = true)\n |-- article: string (nullable = true)\n |-- contributed_to_accident: string (nullable = true)\n |-- race: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- driver_city: string (nullable = true)\n |-- driver_state: string (nullable = true)\n |-- dl_state: string (nullable = true)\n |-- arrest_type: string (nullable = true)\n |-- geolocation: string (nullable = true)\n\n+------------+------------+------+--------------------+--------------------+---------------+--------+---------+--------+-----+---------------+---------------+-----+------------------+------+------------------+-------+---------+-----+---------------+----+----+-----+-----+--------------+---------+--------------------+-----------------------+-----+------+-----------+------------+--------+-----------------+-----------+\n|date_of_stop|time_of_stop|agency|           subagency|         description|       location|latitude|longitude|accident|belts|personal_injury|property_damage|fatal|commercial_license|hazmat|commercial_vehicle|alcohol|work_zone|state|    vehicletype|year|make|model|color|violation_type|   charge|             article|contributed_to_accident| race|gender|driver_city|driver_state|dl_state|      arrest_type|geolocation|\n+------------+------------+------+--------------------+--------------------+---------------+--------+---------+--------+-----+---------------+---------------+-----+------------------+------+------------------+-------+---------+-----+---------------+----+----+-----+-----+--------------+---------+--------------------+-----------------------+-----+------+-----------+------------+--------+-----------------+-----------+\n|  2013-09-24|    17:11:00|   MCP|3rd district, Sil...|DRIVING VEHICLE O...|8804 FLOWER AVE|    null|     null|   false|false|          false|          false|false|             false| false|             false|  false|    false|   MD|02 - Automobile|2008|FORD|   4S|BLACK|      Citation|13-401(h)|Transportation Ar...|                  false|BLACK|     M|TAKOMA PARK|          MD|      MD|A - Marked Patrol|       null|\n+------------+------------+------+--------------------+--------------------+---------------+--------+---------+--------+-----+---------------+---------------+-----+------------------+------+------------------+-------+---------+-----+---------------+----+----+-----+-----+--------------+---------+--------------------+-----------------------+-----+------+-----------+------------+--------+-----------------+-----------+\n\n"}]}},{"text":"\n//registramos el data frame como una tabla temporal con el alias \"df_Table\"\ndf.registerTempTable(\"df_table\")\n\n//lanzamos una consulta SQL filtrando por personal_injury=true y agrupando por marca,modelo y color para hacer\n// un COUNT()\nval dfRES = sqlContext.sql(\"\"+\n                \"SELECT \"+\n                    \"make, \"+\n                    \"model, \"+\n                    \"color, \"+\n                    \"COUNT(color) AS num_accidents \"+\n                \"FROM df_table \"+\n                \"WHERE personal_injury=true \"+\n                \"GROUP BY make, model, color \"+\n                \"ORDER BY COUNT(color) DESC \"\n                )\n                \ndfRES.show()","user":"anonymous","dateUpdated":"2018-11-02T09:45:43+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541151217764_-1603003955","id":"20181102-093337_1942818667","dateCreated":"2018-11-02T09:33:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6498","dateFinished":"2018-11-02T09:45:44+0000","dateStarted":"2018-11-02T09:45:43+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"warning: there was one deprecation warning; re-run with -deprecation for details\ndfRES: org.apache.spark.sql.DataFrame = [make: string, model: string ... 2 more fields]\n+--------+--------+-----------+-------------+\n|    make|   model|      color|num_accidents|\n+--------+--------+-----------+-------------+\n|   SUNNY|  NINGBO|        RED|            6|\n|   ACURA| INTEGRA|      BLACK|            5|\n|   HONDA|   CIVIC|       GRAY|            5|\n|CHRYSLER| SEBRING|      WHITE|            5|\n|    MITS|  LANCER|       GRAY|            5|\n|    FORD|EXPLORER|      GREEN|            5|\n|     KIA|   TRUCK|      BLACK|            4|\n|CHRYSLER|PACIFICA|BLUE, LIGHT|            4|\n|   DODGE|  DAKOTA|        RED|            4|\n|   HONDA|   PILOT|       GRAY|            4|\n|   HONDA|  ACCORD|       BLUE|            3|\n|    TOYO|   CAMRY|     SILVER|            3|\n|    ACUR|     RDX|     SILVER|            3|\n|INFINITI|   SEDAN|       GRAY|            3|\n|  TOYOTA| COROLLA|        TAN|            3|\n|  TOYOTA| COROLLA|     SILVER|            3|\n|    HOND|      4S|      BLACK|            2|\n|   MAZDA|     626|     SILVER|            2|\n|   HONDA|   CIVIC|      BLACK|            2|\n|  TOYOTA| COROLLA|        RED|            2|\n+--------+--------+-----------+-------------+\nonly showing top 20 rows\n\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541151837420_635000487","id":"20181102-094357_939317310","dateCreated":"2018-11-02T09:43:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6869","text":"//añadimos al dataframe de los datos la columna \"dr\" aplicando un DENSE_RANK()\n//por Count descendientemente\ndfRES.registerTempTable(\"dfRES\")\nval dfDataDR = sqlContext.sql(\"\"+\n                \"SELECT \"+\n                    \"*, \"+\n                    \"DENSE_RANK() OVER  (ORDER BY num_accidents DESC) AS dr \"+\n                \"FROM dfRES\"\n                )\ndfDataDR.show()","dateUpdated":"2018-11-02T09:46:04+0000","dateFinished":"2018-11-02T09:46:06+0000","dateStarted":"2018-11-02T09:46:04+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"warning: there was one deprecation warning; re-run with -deprecation for details\ndfDataDR: org.apache.spark.sql.DataFrame = [make: string, model: string ... 3 more fields]\n+--------+--------+-----------+-------------+---+\n|    make|   model|      color|num_accidents| dr|\n+--------+--------+-----------+-------------+---+\n|   SUNNY|  NINGBO|        RED|            6|  1|\n|CHRYSLER| SEBRING|      WHITE|            5|  2|\n|    MITS|  LANCER|       GRAY|            5|  2|\n|   ACURA| INTEGRA|      BLACK|            5|  2|\n|   HONDA|   CIVIC|       GRAY|            5|  2|\n|    FORD|EXPLORER|      GREEN|            5|  2|\n|     KIA|   TRUCK|      BLACK|            4|  3|\n|CHRYSLER|PACIFICA|BLUE, LIGHT|            4|  3|\n|   DODGE|  DAKOTA|        RED|            4|  3|\n|   HONDA|   PILOT|       GRAY|            4|  3|\n|  TOYOTA| COROLLA|        TAN|            3|  4|\n|  TOYOTA| COROLLA|     SILVER|            3|  4|\n|    ACUR|     RDX|     SILVER|            3|  4|\n|    TOYO|   CAMRY|     SILVER|            3|  4|\n|   HONDA|  ACCORD|       BLUE|            3|  4|\n|INFINITI|   SEDAN|       GRAY|            3|  4|\n|   MAZDA|     626|     SILVER|            2|  5|\n|  TOYOTA| COROLLA|        RED|            2|  5|\n|    HYUN|      2S|      BLACK|            2|  5|\n|    CHEV|      SU|      BLACK|            2|  5|\n+--------+--------+-----------+-------------+---+\nonly showing top 20 rows\n\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541151964901_-668964965","id":"20181102-094604_1859495866","dateCreated":"2018-11-02T09:46:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6998","text":"//añadimos al dataframe la columna \"rn\" aplicando un ROW_NUMBER() ordenando\n//por Count de manera descendente y \"marca -modelo-color\" ascendente\nval dfDataRN = sqlContext.sql(\"\"+\n                \"SELECT \"+\n                    \"*, \"+\n                    \"ROW_NUMBER() OVER  (ORDER BY num_accidents DESC) AS rn \"+\n                \"FROM dfRES\"\n                )\ndfDataRN.show()","dateUpdated":"2018-11-02T09:46:20+0000","dateFinished":"2018-11-02T09:46:20+0000","dateStarted":"2018-11-02T09:46:20+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"dfDataRN: org.apache.spark.sql.DataFrame = [make: string, model: string ... 3 more fields]\n+--------+--------+-----------+-------------+---+\n|    make|   model|      color|num_accidents| rn|\n+--------+--------+-----------+-------------+---+\n|   SUNNY|  NINGBO|        RED|            6|  1|\n|CHRYSLER| SEBRING|      WHITE|            5|  2|\n|    MITS|  LANCER|       GRAY|            5|  3|\n|   ACURA| INTEGRA|      BLACK|            5|  4|\n|   HONDA|   CIVIC|       GRAY|            5|  5|\n|    FORD|EXPLORER|      GREEN|            5|  6|\n|     KIA|   TRUCK|      BLACK|            4|  7|\n|CHRYSLER|PACIFICA|BLUE, LIGHT|            4|  8|\n|   DODGE|  DAKOTA|        RED|            4|  9|\n|   HONDA|   PILOT|       GRAY|            4| 10|\n|  TOYOTA| COROLLA|        TAN|            3| 11|\n|  TOYOTA| COROLLA|     SILVER|            3| 12|\n|    ACUR|     RDX|     SILVER|            3| 13|\n|    TOYO|   CAMRY|     SILVER|            3| 14|\n|   HONDA|  ACCORD|       BLUE|            3| 15|\n|INFINITI|   SEDAN|       GRAY|            3| 16|\n|   MAZDA|     626|     SILVER|            2| 17|\n|  TOYOTA| COROLLA|        RED|            2| 18|\n|    HYUN|      2S|      BLACK|            2| 19|\n|    CHEV|      SU|      BLACK|            2| 20|\n+--------+--------+-----------+-------------+---+\nonly showing top 20 rows\n\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541151980017_-1980558641","id":"20181102-094620_656906453","dateCreated":"2018-11-02T09:46:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7081","text":"dfDataDR.registerTempTable(\"dfDataDR\")\n\n//aplicamos otro ROW_NUMBER, pero esta vez sobre el dataframe donde previamente hemos aplicado el DENSE_RANK()\n// para seleccionar las primeras filas de cada conjunto de datos en el Count\nval dfData_RN_over_DR = sqlContext.sql(\"\"+\n                \"SELECT \"+\n                    \"*, \"+\n                    \"ROW_NUMBER() OVER  (PARTITION BY dr ORDER BY dr DESC) AS rn \"+\n                \"FROM dfDataDR\"\n                )\ndfData_RN_over_DR.show()","dateUpdated":"2018-11-02T09:46:35+0000","dateFinished":"2018-11-02T09:46:36+0000","dateStarted":"2018-11-02T09:46:35+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"warning: there was one deprecation warning; re-run with -deprecation for details\ndfData_RN_over_DR: org.apache.spark.sql.DataFrame = [make: string, model: string ... 4 more fields]\n+--------+--------+-----------+-------------+---+---+\n|    make|   model|      color|num_accidents| dr| rn|\n+--------+--------+-----------+-------------+---+---+\n|   SUNNY|  NINGBO|        RED|            6|  1|  1|\n|CHRYSLER| SEBRING|      WHITE|            5|  2|  1|\n|    MITS|  LANCER|       GRAY|            5|  2|  2|\n|   ACURA| INTEGRA|      BLACK|            5|  2|  3|\n|   HONDA|   CIVIC|       GRAY|            5|  2|  4|\n|    FORD|EXPLORER|      GREEN|            5|  2|  5|\n|     KIA|   TRUCK|      BLACK|            4|  3|  1|\n|CHRYSLER|PACIFICA|BLUE, LIGHT|            4|  3|  2|\n|   DODGE|  DAKOTA|        RED|            4|  3|  3|\n|   HONDA|   PILOT|       GRAY|            4|  3|  4|\n|  TOYOTA| COROLLA|        TAN|            3|  4|  1|\n|  TOYOTA| COROLLA|     SILVER|            3|  4|  2|\n|    ACUR|     RDX|     SILVER|            3|  4|  3|\n|    TOYO|   CAMRY|     SILVER|            3|  4|  4|\n|   HONDA|  ACCORD|       BLUE|            3|  4|  5|\n|INFINITI|   SEDAN|       GRAY|            3|  4|  6|\n|   MAZDA|     626|     SILVER|            2|  5|  1|\n|  TOYOTA| COROLLA|        RED|            2|  5|  2|\n|    HYUN|      2S|      BLACK|            2|  5|  3|\n|    CHEV|      SU|      BLACK|            2|  5|  4|\n+--------+--------+-----------+-------------+---+---+\nonly showing top 20 rows\n\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541151995027_-2046888693","id":"20181102-094635_1203258276","dateCreated":"2018-11-02T09:46:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7162","text":"dfData_RN_over_DR.registerTempTable(\"dfData_RN_over_DR\")\n\n//nos quedamos solo con las filas donde rn sea igual a 1 para despreciar el resto\nval dfData_RN_over_DR_filtered = sqlContext.sql(\"\"+\n                \"SELECT \"+\n                    \"* \"+\n                \"FROM dfData_RN_over_DR \"+\n                \"WHERE rn = 1\"\n                ).drop(\"rn\").drop(\"dr\")\ndfData_RN_over_DR_filtered.show()\n\n/*\n#primeras ocurrencias de cada conjunto de número de accidentes:\n#ejemplo de lo que debe mostrar:\n#+-----+--------------------+---+---+\n#|Count|Mark - Model - Color| dr| rn|\n#+-----+--------------------+---+---+\n#|    6|  [SUNNY,NINGBO,RED]|  1|  1|<---\n#|    5|[ACURA,INTEGRA,BL...|  2|  1|<---\n#|    5|[CHRYSLER,SEBRING...|  2|  2|\n#|    5|[FORD,EXPLORER,GR...|  2|  3|\n#|    5|  [HONDA,CIVIC,GRAY]|  2|  4|\n#|    5|  [MITS,LANCER,GRAY]|  2|  5|\n#|    4|[CHRYSLER,PACIFIC...|  3|  1|<---\n#|    4|  [DODGE,DAKOTA,RED]|  3|  2|\n#|    4|  [HONDA,PILOT,GRAY]|  3|  3|\n#|    4|   [KIA,TRUCK,BLACK]|  3|  4|\n#|    3|   [ACUR,RDX,SILVER]|  4|  1|<---\n#|    3| [HONDA,ACCORD,BLUE]|  4|  2|\n#|    3|[INFINITI,SEDAN,G...|  4|  3|\n#|    3| [TOYO,CAMRY,SILVER]|  4|  4|\n#|    3|[TOYOTA,COROLLA,S...|  4|  5|\n#|    3|[TOYOTA,COROLLA,TAN]|  4|  6|\n#|    2|     [CHEV,SU,BLACK]|  5|  1|<---\n#|    2|[FORD,EXPEDITION,...|  5|  2|\n#|    2|     [HOND,4S,BLACK]|  5|  3|\n#|    2| [HONDA,CIVIC,BLACK]|  5|  4|\n#+-----+--------------------+---+---+\n*/\n","dateUpdated":"2018-11-02T09:46:49+0000","dateFinished":"2018-11-02T09:46:50+0000","dateStarted":"2018-11-02T09:46:49+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"warning: there was one deprecation warning; re-run with -deprecation for details\ndfData_RN_over_DR_filtered: org.apache.spark.sql.DataFrame = [make: string, model: string ... 2 more fields]\n+--------+-------+------+-------------+\n|    make|  model| color|num_accidents|\n+--------+-------+------+-------------+\n|   SUNNY| NINGBO|   RED|            6|\n|CHRYSLER|SEBRING| WHITE|            5|\n|     KIA|  TRUCK| BLACK|            4|\n|  TOYOTA|COROLLA|   TAN|            3|\n|   MAZDA|    626|SILVER|            2|\n|   LEXUS|  RX350|   TAN|            1|\n+--------+-------+------+-------------+\n\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541152009298_-622132868","id":"20181102-094649_887441882","dateCreated":"2018-11-02T09:46:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7245","text":"//para establecer un ranking en base al numero de ocurrencias y poder mostrar despues\n//del join los 3 primeros coches con mas accidentes\n\nval rankingSequence = Seq(Row(1),Row(2),Row(3))\nval schema = List(StructField(\"rn\", IntegerType, true))\nval dfRanking = spark.createDataFrame(spark.sparkContext.parallelize(rankingSequence), StructType(schema))\n//dfRanking.show()\n\n//hacemos el join de los dos dataframes llamando a la funcion joinDataFrames\n//y cruzando por la columna \"rn\" para que nos saque los 3 coches con mas\n//accidentes\nval DF_join = joinDataFrames(dfDataRN,dfRanking,JOIN_COLUMN)\n\n\n//renombramos la columna\nval DF_joinRES = DF_join.orderBy(JOIN_COLUMN).withColumnRenamed(JOIN_COLUMN, \"Ranking\")\nprint(\" *** RANKING ***\")\nDF_joinRES.show()\n\n/*\n#ejemplo de lo que debe mostrar:\n#+-----+--------------------+---+\n#|Count|Mark - Model - Color| rn|\n#+-----+--------------------+---+\n#|    6|  [SUNNY,NINGBO,RED]|  1|<---\n#|    5|[ACURA,INTEGRA,BL...|  2|<---\n#|    5|[CHRYSLER,SEBRING...|  3|<---\n#|    5|[FORD,EXPLORER,GR...|  4|\n#|    5|  [HONDA,CIVIC,GRAY]|  5|\n#|    5|  [MITS,LANCER,GRAY]|  6|\n*/\n\n\n","dateUpdated":"2018-11-02T09:46:54+0000","dateFinished":"2018-11-02T09:46:56+0000","dateStarted":"2018-11-02T09:46:54+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rankingSequence: Seq[org.apache.spark.sql.Row] = List([1], [2], [3])\nschema: List[org.apache.spark.sql.types.StructField] = List(StructField(rn,IntegerType,true))\ndfRanking: org.apache.spark.sql.DataFrame = [rn: int]\nDF_join: org.apache.spark.sql.DataFrame = [make: string, model: string ... 3 more fields]\nDF_joinRES: org.apache.spark.sql.DataFrame = [make: string, model: string ... 3 more fields]\n *** RANKING ***+--------+-------+-----+-------------+-------+\n|    make|  model|color|num_accidents|Ranking|\n+--------+-------+-----+-------------+-------+\n|   SUNNY| NINGBO|  RED|            6|      1|\n|CHRYSLER|SEBRING|WHITE|            5|      2|\n|    MITS| LANCER| GRAY|            5|      3|\n+--------+-------+-----+-------------+-------+\n\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1541152014388_136992036","id":"20181102-094654_2070522182","dateCreated":"2018-11-02T09:46:54+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7328"}],"name":"scala_code_SQL","id":"2DWGKBZEW","angularObjects":{"2DV35SYUN:shared_process":[],"2DW5GUUDK:shared_process":[],"2DWRCPEYR:shared_process":[],"2DU7W16TK:shared_process":[],"2DWB9M8YK:shared_process":[],"2DVCTGJKH:shared_process":[],"2DX9RP6WP:shared_process":[],"2DX57KEHM:shared_process":[],"2DW7BCQYC:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}